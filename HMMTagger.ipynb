{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2e23b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "WORDTAG = 'WORDTAG'\n",
    "GRAM1 = '1-GRAM'\n",
    "GRAM2 = '2-GRAM'\n",
    "GRAM3 = '3-GRAM'\n",
    "RARE = '_RARE_'\n",
    "RARE_THRESHOLD = 5\n",
    "# A I-LOC might be followed by B-LOC if a new location follow one immediately after another one                                                                                                              \n",
    "# There are 9 tags to consider                                                                                                                                                                               \n",
    "TAGS = [\n",
    "    'I-PER',\n",
    "    'I-ORG',\n",
    "    'I-LOC',\n",
    "    'I-MISC',\n",
    "    'B-PER',\n",
    "    'B-ORG',\n",
    "    'B-LOC',\n",
    "    'B-MISC',\n",
    "    'O'\n",
    "]\n",
    "# The start and stop symbols                                                                                                                                                                                 \n",
    "START = '*'\n",
    "STOP = 'STOP'\n",
    "\n",
    "FILL_IN = '_FILL_IN_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13481a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_counts[(u, v, w)] = count(u, v, w)\n",
    "# q_counts[[u, v]] = count(u, v)\n",
    "# e_counts[(u, x)] = count(u, x)\n",
    "def get_q_e_counts(counts_file_name = 'ner.counts'):\n",
    "    f = open(counts_file_name)\n",
    "\n",
    "    q_counts = defaultdict(int)\n",
    "    e_counts = defaultdict(int)\n",
    "\n",
    "    for l in f:\n",
    "        l = l.strip().split(' ')\n",
    "        ct = int(l[0])\n",
    "        if l[1] == WORDTAG:\n",
    "            y, x = l[-2], l[-1]\n",
    "            e_counts[y] += ct\n",
    "            e_counts[(y, x)] += ct\n",
    "        else:\n",
    "            if l[1] == GRAM1:\n",
    "                y1 = l[-1]\n",
    "                q_counts[y1] += ct\n",
    "            elif l[1] == GRAM2:\n",
    "                y1, y2 = l[-2], l[-1]\n",
    "                q_counts[(y1, y2)] += ct\n",
    "            else:\n",
    "                y1, y2, y3 = l[-3], l[-2], l[-1]\n",
    "                q_counts[(y1, y2, y3)] += ct\n",
    "    f.close()\n",
    "\n",
    "    return q_counts, e_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a10f8919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This transforms the data into one involving the rare words                                                                                                                                                 \n",
    "# We then run the count_freqs.py utility to get the new counts across the corpus                                                                                                                             \n",
    "def transform_data(e_counts):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        e_counts: A dictionary with counts(y, x) and counts(y)\n",
    "    Output:\n",
    "        Nothing; write to g\n",
    "    \"\"\"\n",
    "    f = open('ner_train.dat', 'r')\n",
    "    g = open('ner_train_rare.dat', 'w')\n",
    "\n",
    "    # Get the counts per word; this is used to get the rare words                                                                                                                                            \n",
    "    # What words need to be replaced with a rare word?\n",
    "    # Note that we do here is take all counts of (u, x) for all u to get the count for x\n",
    "    x_counts = defaultdict(int)\n",
    "    for k, ct in e_counts.items():\n",
    "        if type(k) != str:\n",
    "            _, x = k\n",
    "            x_counts[x] += ct\n",
    "\n",
    "    # Loop through the data file and transform it given whatever words are rare                                                                                                                              \n",
    "    for l in f:\n",
    "        if not l.strip():\n",
    "            g.write('\\n')\n",
    "        else:\n",
    "            l = l.strip().split(' ')\n",
    "            x, y = l[-2], l[-1]\n",
    "            if x_counts[x] < 5:\n",
    "                g.write('{} {}\\n'.format(RARE, y))\n",
    "            else:\n",
    "                g.write('{} {}\\n'.format(x, y))\n",
    "\n",
    "    f.close()\n",
    "    g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db045576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the probabilities e(x_t | y_t)                                                                                                                                                                   \n",
    "def get_emission(y, x, e_counts, x_counts):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        y: A tag\n",
    "        x: A word\n",
    "        e_counts: A dictionary with counts(y, x) and counts(y)\n",
    "        x_counts: A dictionary with counts(x)\n",
    "    Output:\n",
    "        The probabilty e(x|y) or e(RARE|y) is x is rare\n",
    "        This is vartheta(x | y) in the lecture\n",
    "    \"\"\"\n",
    "    # If a rare word, return e(RARE | y)\n",
    "    if x_counts[x] < RARE_THRESHOLD:\n",
    "        return float(e_counts[(y, RARE)]) / e_counts[y] if e_counts[y] else 0.0\n",
    "    # Otherwise, return e(x | y)                                                                                                                                                                             \n",
    "    return float(e_counts[(y, x)]) / e_counts[y] if e_counts[y] != 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5487d96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not that for the baseline decoder we don't need Dynamic Programming\n",
    "# We have max_{y1, ..., YT} = max_{y1}(e(x1|y1))...max_{yT}(e(xT|yT))\n",
    "def baseline_ner_tagger(\n",
    "        counts_file_name = 'ner_rare.counts'\n",
    "):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        counts_file_name: The counts file we use\n",
    "    Output:\n",
    "        Nothing; write to a new file \"x, y, log(e(x|y))\" where y is the optimal tag for x\n",
    "    \"\"\"\n",
    "    f = open('ner_dev.dat', 'r')\n",
    "    g = open('ner_dev.baseline_predictions', 'w')\n",
    "\n",
    "    _, e_counts = get_q_e_counts(counts_file_name)\n",
    "    \n",
    "    # Get the counts per word; this is used to get the rare words                                                                                                                                            \n",
    "    # What words need to be replaced with a rare word?\n",
    "    # Note that we do here is take all counts of (u, x) for all u to get the count for x\n",
    "    x_counts = defaultdict(int)\n",
    "    for k, ct in e_counts.items():\n",
    "        if type(k) != str:\n",
    "            _, x = k\n",
    "            x_counts[x] += ct\n",
    "\n",
    "    for l in f:\n",
    "        if not l or l == '\\n':\n",
    "            g.write('\\n')\n",
    "        else:\n",
    "            # We can do this for each word: find the highest probability tag\n",
    "            l = l.strip().split(' ')\n",
    "            x = l[-1]\n",
    "            y_best = None\n",
    "            p_best = float('-inf')\n",
    "            for y in TAGS:\n",
    "                p = get_emission(y, x, e_counts, x_counts)\n",
    "                if y_best is None or p > p_best:\n",
    "                    y_best = y\n",
    "                    p_best = p\n",
    "            g.write('{} {} {}\\n'.format(x, y_best, np.log(p_best)))\n",
    "    f.close()\n",
    "    g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "377210b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the probabilities p(y_t | y_{t-1}, y_{t-2})                                                                                                                                                      \n",
    "def get_transition(y1, y2, y3, q_counts):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        y1: The tag two away from the output tag\n",
    "        y2: The tag right before the output tag\n",
    "        y3: The output tag\n",
    "        q_counts: The counts we need for two or 3 tags beting seen together\n",
    "    Output:\n",
    "        q(w | v, u) which is theta(w | v, u) in the lecture\n",
    "    \"\"\"\n",
    "    if (y1, y2) not in q_counts:\n",
    "        return 0.0\n",
    "    return float(q_counts[(y1, y2, y3)]) / q_counts[(y1, y2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5cad2892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmm_ner_tagger(\n",
    "        counts_file_name = 'ner_rare.counts'\n",
    "):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        counts_file_name: The counts file we use\n",
    "    Output:\n",
    "        Nothing; write to a new file \"x_t, y_t, log(pi(t, y_{t-1}, y_t))\" where y_t is the optimal tag for x_t\n",
    "        Note that {y_t} is the optimal sequence here, computed by Dynamic Programming\n",
    "    \"\"\"\n",
    "    f = open('ner_dev.dat', 'r')\n",
    "    g = open('ner_dev.hmm_predictions', 'w')\n",
    "\n",
    "    q, e = get_q_e_counts(counts_file_name)\n",
    "\n",
    "    # Get the counts per word; this is used to identify                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
    "    x_counts = defaultdict(int)\n",
    "    for k, ct in e.items():\n",
    "        if type(k) != str:\n",
    "            _, x = k\n",
    "            x_counts[x] += ct\n",
    "\n",
    "    # Can use log probabilities here                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
    "    # Reset all variables                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "    pi = defaultdict(float)\n",
    "    bp = defaultdict(str)\n",
    "    pi[(0, START, START)] = 1.0\n",
    "    T = 0\n",
    "    xT = []\n",
    "    for l in f:\n",
    "        if not l or l == '\\n':\n",
    "            # We have an empty line; if xT has data in it then decode it by working backwords                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
    "            if xT:\n",
    "                # Define the default values of v and w here                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
    "                pi_max = float('-inf')\n",
    "                v_max = None\n",
    "                w_max = None\n",
    "\n",
    "                # Here we define the tag sequence of v and w\n",
    "                # pi(T, v, w) + np.log(get_transition(v, w, STOP, q)) is what we want to maximize\n",
    "                # We need v and w and from this we need to work back\n",
    "                v_tags = [START] if T == 1 else TAGS\n",
    "                w_tags = TAGS\n",
    "\n",
    "                for v in v_tags:\n",
    "                    for w in w_tags:\n",
    "                        pi_temp = pi[(T, v, w)] + np.log(get_transition(v, w, STOP, q))\n",
    "                        if pi_temp > pi_max or v_max is None or w_max is None:\n",
    "                            v_max = v\n",
    "                            w_max = w\n",
    "                            pi_max = pi_temp\n",
    "                \n",
    "                # Set yT be the sequence [v_max, w_max] if T > 1 and [w_max] otherwise\n",
    "                yT = [v_max, w_max] if T > 1 else [w_max]\n",
    "\n",
    "                \"\"\"\n",
    "                Use backpointers to get the sequence we seek \n",
    "                This is the highest probability tag sequence (y1,..., yT)\n",
    "                Remember we just found v_max and w_max and we have \n",
    "                pi(T, v_max, w_max) = np.log(e(xT | w_max)) + \\max_{u}(q(w_max | v_max, y)*pi(T-1, u, v_max))\n",
    "                We need u, which should be u_max = bp[(T, v_max, w_max)]\n",
    "                We append this to yT to get [u_max, v_max, w_max]\n",
    "                We continue this process on until T = 1 (use a loop)\n",
    "                \"\"\"\n",
    "                for t in range(T-2, 0, -1):\n",
    "                    yT = [bp[(t+2, yT[0], yT[1])]] + yT\n",
    "                \n",
    "                log_pT = []                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
    "                assert(T == len(xT))\n",
    "                assert(len(yT) == len(xT))\n",
    "                \n",
    "                \"\"\"\n",
    "                We want to get the log probability of the sequence\n",
    "                For example, when we are at x1 this is\n",
    "                np.log(q(y1, START, START)) + np.log(e(x1|y1))\n",
    "                \"\"\"\n",
    "                for t in range(len(xT)):\n",
    "                    if t == 0:\n",
    "                        log_pT.append(\n",
    "                            np.log(get_transition(START, START, yT[t], q_counts) * get_emission(yT[t], xT[t], e_counts, x_counts))\n",
    "                        )\n",
    "                    elif t == 1:\n",
    "                        log_pT.append(\n",
    "                            log_pT[-1] +\n",
    "                            np.log(\n",
    "                                get_transition(START, yT[t-1], yT[t], q_counts) * get_emission(yT[t], xT[t], e_counts, x_counts)\n",
    "                            )\n",
    "                        )\n",
    "                    else:\n",
    "                        log_pT.append(\n",
    "                            log_pT[-1] +\n",
    "                            np.log(\n",
    "                                get_transition(yT[t-2], yT[t-1], yT[t], q_counts) * get_emission(yT[t], xT[t], e_counts, x_counts)\n",
    "                            )\n",
    "                        )\n",
    "                for xt, yt, log_pt in zip(xT, yT, log_pT):\n",
    "                    g.write('{} {} {}\\n'.format(xt, yt, log_pt))\n",
    "                g.write('\\n')\n",
    "\n",
    "\n",
    "            # Reset all variables\n",
    "            # For the next sentence, we'll append words as we see them and compute these \n",
    "            pi = defaultdict(float)\n",
    "            bp = defaultdict(str)\n",
    "            pi[(0, START, START)] = 1.0\n",
    "            T = 0\n",
    "            xT = []\n",
    "        else:\n",
    "            # This is the forward step of Dynamic Programming, where we go from T-1 -> T\n",
    "            l = l.strip().split(' ')\n",
    "            #print(l)\n",
    "            T += 1\n",
    "            xt = l[-1]\n",
    "            xT.append(xt)\n",
    "\n",
    "            # q(w | v, u)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "            # What can u be? Consider q(w | v, u) when T = 1 or T = 2 vs more                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
    "            u_tags = [START] if T <= 2 else TAGS\n",
    "            # What can v be? Consider q(w | v, u) when T = 1 [Ovs more                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
    "            v_tags = [START] if T == 1 else TAGS\n",
    "            # What can w be? w can only be a true TAG, never START                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
    "            w_tags = TAGS\n",
    "\n",
    "            \"\"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
    "            For this we use the recursion below:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
    "            v, w in v_tags, w_tags while u is over u_tags\n",
    "\n",
    "            The probability recursion:\n",
    "            pi(t, v, w) = e(xt | w) max_{u}{q(w | v, u) * pi(t-1, u, v)}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
    "\n",
    "            Becomes the log recursion:\n",
    "            pi(t, v, w) = log e(xt | w) + max_{u}{log q(w | v, u)  + pi(t-1, u, v)}                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
    "\n",
    "            We use logs below to make it easier and avoid overflow                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
    "            \"\"\"\n",
    "            for v in v_tags:\n",
    "                for w in w_tags:\n",
    "                    # e(x | w); this term is not in the max                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
    "                    e_temp = get_emission(w, xt, e_counts, x_counts)\n",
    "\n",
    "                    # pi(t, v, w) = log e(xt | w)  + max_{u}{log q(w | v, u)  + pi(t-1, u, v)}                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
    "                    pi_max = float('-inf')\n",
    "                    u_max = None\n",
    "\n",
    "                    # Do the max with respect to u                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
    "                    for u in u_tags:\n",
    "                        # q(w | v, u)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
    "                        q_temp = get_transition(u, v, w, q_counts)\n",
    "                        pi_temp = np.log(e_temp) + np.log(q_temp)  + pi[(T-1, u, v)]\n",
    "                        if u_max is None or pi_temp > pi_max:\n",
    "                            u_max = u\n",
    "                            pi_max = pi_temp\n",
    "\n",
    "                    # The arg max of max_{u}{log q(w | v, u)  + pi(t-1, u, v)}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
    "                    bp[(T, v, w)] = u_max\n",
    "\n",
    "                    # The log probability of ending in (v, w) at time T                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
    "                    pi[(T, v, w)] = pi_max\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf320ec9",
   "metadata": {},
   "source": [
    "# Run code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c338431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  217662 ner_train.dat\r\n"
     ]
    }
   ],
   "source": [
    "# This gets the number of lines in new_train.dat\n",
    "!wc -l ner_train.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "64519726",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python count_freqs.py ner_train.dat > ner.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb39221e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 WORDTAG I-ORG EU\r\n",
      "1 WORDTAG O rejects\r\n",
      "84 WORDTAG I-MISC German\r\n",
      "30 WORDTAG O call\r\n",
      "3382 WORDTAG O to\r\n",
      "5 WORDTAG O boycott\r\n",
      "78 WORDTAG I-MISC British\r\n",
      "3 WORDTAG O lamb\r\n",
      "7362 WORDTAG O .\r\n",
      "31 WORDTAG I-PER Peter\r\n"
     ]
    }
   ],
   "source": [
    "!head ner.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90432dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24968 ner.counts\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l ner.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dcff8005",
   "metadata": {},
   "outputs": [],
   "source": [
    " # This does the flow of everything, you might want to comment out certain parts                                                                                                                                                                                                       \n",
    "q_counts, e_counts = get_q_e_counts('ner.counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca72655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "079f75ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the new data and replace all rare words with _RARE_                                                                                                                                                                                                                             \n",
    "transform_data(e_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2efc42d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  217662 ner_train_rare.dat\r\n"
     ]
    }
   ],
   "source": [
    "# Should be the same number of lines as above\n",
    "!wc -l ner_train_rare.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bccb0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc95a056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the count_freqs helper again to get the new counts                                                                                                                                                                                                                              \n",
    "# This requires a run outside of this                                                                                                                                                                                                                                                 \n",
    "!python count_freqs.py ner_train_rare.dat > ner_rare.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d6cf80b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    5959 ner_rare.counts\r\n"
     ]
    }
   ],
   "source": [
    "# Many words will get mapped to _RARE_, so it is fairly simple\n",
    "!wc -l ner_rare.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76a7414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0596a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the rare counts for each word\n",
    "# These will allow us to get the new probabilities\n",
    "q_counts, e_counts = get_q_e_counts('ner_rare.counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a810eae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "283a1c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get baseline model's performance                                                                                                                                                                                                                                                            \n",
    "baseline_ner_tagger('ner_rare.counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8385b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14043 NEs. Expected 5931 NEs; Correct: 3117.\r\n",
      "\r\n",
      "\t precision \trecall \t\tF1-Score\r\n",
      "Total:\t 0.221961\t0.525544\t0.312106\r\n",
      "PER:\t 0.435451\t0.231230\t0.302061\r\n",
      "ORG:\t 0.475936\t0.399103\t0.434146\r\n",
      "LOC:\t 0.147750\t0.870229\t0.252612\r\n",
      "MISC:\t 0.491689\t0.610206\t0.544574\r\n"
     ]
    }
   ],
   "source": [
    "# This evaluates the baseline tagger\n",
    "!python eval_ne_tagger.py ner_dev.key ner_dev.baseline_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995dec23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "91ff7c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x8/2_vxppc52znb82mg86nv4y000000gp/T/ipykernel_27138/4141018020.py:149: RuntimeWarning: divide by zero encountered in log\n",
      "  pi_temp = np.log(e_temp) + np.log(q_temp)  + pi[(T-1, u, v)]\n",
      "/var/folders/x8/2_vxppc52znb82mg86nv4y000000gp/T/ipykernel_27138/4141018020.py:47: RuntimeWarning: divide by zero encountered in log\n",
      "  pi_temp = pi[(T, v, w)] + np.log(get_transition(v, w, STOP, q))\n"
     ]
    }
   ],
   "source": [
    "# Get HMM model's performance                                                                                                                                                                                                                                                                 \n",
    "hmm_ner_tagger('ner_rare.counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e1e81f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4704 NEs. Expected 5931 NEs; Correct: 3649.\r\n",
      "\r\n",
      "\t precision \trecall \t\tF1-Score\r\n",
      "Total:\t 0.775723\t0.615242\t0.686225\r\n",
      "PER:\t 0.763928\t0.596844\t0.670128\r\n",
      "ORG:\t 0.611855\t0.478326\t0.536913\r\n",
      "LOC:\t 0.876458\t0.696292\t0.776056\r\n",
      "MISC:\t 0.830065\t0.689468\t0.753262\r\n"
     ]
    }
   ],
   "source": [
    "# This evaluates the HMM tagger; performance should be about double that of the baseline\n",
    "!python eval_ne_tagger.py ner_dev.key ner_dev.hmm_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9e1b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "858f31eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, e = get_q_e_counts('ner.counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "71bdf96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('O', 'STOP')\n",
      "('I-PER', 'STOP')\n",
      "('I-ORG', 'STOP')\n",
      "('I-LOC', 'STOP')\n",
      "('I-MISC', 'STOP')\n",
      "('B-ORG', 'STOP')\n",
      "('O', 'O', 'STOP')\n",
      "('I-PER', 'I-PER', 'STOP')\n",
      "('I-LOC', 'O', 'STOP')\n",
      "('I-ORG', 'O', 'STOP')\n",
      "('*', 'O', 'STOP')\n",
      "('I-PER', 'O', 'STOP')\n",
      "('I-ORG', 'I-ORG', 'STOP')\n",
      "('O', 'I-LOC', 'STOP')\n",
      "('I-MISC', 'O', 'STOP')\n",
      "('*', 'I-ORG', 'STOP')\n",
      "('*', 'I-LOC', 'STOP')\n",
      "('O', 'I-PER', 'STOP')\n",
      "('*', 'I-PER', 'STOP')\n",
      "('I-MISC', 'I-MISC', 'STOP')\n",
      "('O', 'I-ORG', 'STOP')\n",
      "('O', 'I-MISC', 'STOP')\n",
      "('I-LOC', 'I-LOC', 'STOP')\n",
      "('*', 'I-MISC', 'STOP')\n",
      "('B-ORG', 'B-ORG', 'STOP')\n"
     ]
    }
   ],
   "source": [
    "for k, v in q.items():\n",
    "    if 'STOP' in k:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a971e697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'I-ORG': 10001,\n",
       "             'O': 169578,\n",
       "             'I-MISC': 4556,\n",
       "             'I-PER': 11128,\n",
       "             'I-LOC': 8286,\n",
       "             'B-LOC': 11,\n",
       "             'B-MISC': 37,\n",
       "             'B-ORG': 24,\n",
       "             ('*', 'I-ORG'): 2455,\n",
       "             ('*', '*'): 14041,\n",
       "             ('I-ORG', 'O'): 6105,\n",
       "             ('O', 'I-MISC'): 2859,\n",
       "             ('I-MISC', 'O'): 3138,\n",
       "             ('O', 'O'): 138886,\n",
       "             ('O', 'STOP'): 13323,\n",
       "             ('*', 'I-PER'): 1349,\n",
       "             ('I-PER', 'I-PER'): 4528,\n",
       "             ('I-PER', 'STOP'): 242,\n",
       "             ('*', 'I-LOC'): 1581,\n",
       "             ('I-LOC', 'O'): 6917,\n",
       "             ('*', 'O'): 8154,\n",
       "             ('O', 'I-ORG'): 3792,\n",
       "             ('I-ORG', 'I-ORG'): 3704,\n",
       "             ('O', 'I-PER'): 5183,\n",
       "             ('I-PER', 'O'): 6354,\n",
       "             ('O', 'I-LOC'): 5533,\n",
       "             ('I-MISC', 'I-MISC'): 1132,\n",
       "             ('*', 'I-MISC'): 502,\n",
       "             ('I-LOC', 'I-LOC'): 1156,\n",
       "             ('I-ORG', 'STOP'): 169,\n",
       "             ('I-LOC', 'STOP'): 160,\n",
       "             ('I-LOC', 'B-LOC'): 11,\n",
       "             ('B-LOC', 'O'): 10,\n",
       "             ('I-MISC', 'I-ORG'): 39,\n",
       "             ('I-MISC', 'I-LOC'): 10,\n",
       "             ('I-MISC', 'B-MISC'): 35,\n",
       "             ('B-MISC', 'O'): 14,\n",
       "             ('I-ORG', 'I-MISC'): 9,\n",
       "             ('B-MISC', 'I-MISC'): 23,\n",
       "             ('I-MISC', 'STOP'): 141,\n",
       "             ('I-PER', 'I-MISC'): 1,\n",
       "             ('I-MISC', 'I-PER'): 61,\n",
       "             ('I-LOC', 'I-ORG'): 11,\n",
       "             ('I-LOC', 'I-MISC'): 30,\n",
       "             ('I-ORG', 'I-PER'): 6,\n",
       "             ('I-PER', 'I-LOC'): 3,\n",
       "             ('I-LOC', 'I-PER'): 1,\n",
       "             ('I-ORG', 'I-LOC'): 2,\n",
       "             ('I-ORG', 'B-ORG'): 6,\n",
       "             ('B-ORG', 'B-ORG'): 18,\n",
       "             ('B-ORG', 'STOP'): 6,\n",
       "             ('O', 'B-MISC'): 2,\n",
       "             ('B-LOC', 'I-LOC'): 1,\n",
       "             ('*', '*', 'I-ORG'): 2455,\n",
       "             ('*', 'I-ORG', 'O'): 1538,\n",
       "             ('I-ORG', 'O', 'I-MISC'): 35,\n",
       "             ('O', 'I-MISC', 'O'): 2058,\n",
       "             ('I-MISC', 'O', 'O'): 2641,\n",
       "             ('O', 'O', 'O'): 118330,\n",
       "             ('O', 'O', 'I-MISC'): 2419,\n",
       "             ('O', 'O', 'STOP'): 10122,\n",
       "             ('*', '*', 'I-PER'): 1349,\n",
       "             ('*', 'I-PER', 'I-PER'): 727,\n",
       "             ('I-PER', 'I-PER', 'STOP'): 177,\n",
       "             ('*', '*', 'I-LOC'): 1581,\n",
       "             ('*', 'I-LOC', 'O'): 1351,\n",
       "             ('I-LOC', 'O', 'STOP'): 1551,\n",
       "             ('*', '*', 'O'): 8154,\n",
       "             ('*', 'O', 'I-ORG'): 337,\n",
       "             ('O', 'I-ORG', 'I-ORG'): 1586,\n",
       "             ('I-ORG', 'I-ORG', 'O'): 2400,\n",
       "             ('I-ORG', 'O', 'O'): 3901,\n",
       "             ('I-LOC', 'O', 'O'): 4177,\n",
       "             ('O', 'O', 'I-ORG'): 2062,\n",
       "             ('O', 'O', 'I-PER'): 3164,\n",
       "             ('O', 'I-PER', 'I-PER'): 3493,\n",
       "             ('I-PER', 'I-PER', 'O'): 4107,\n",
       "             ('I-PER', 'O', 'O'): 3686,\n",
       "             ('O', 'O', 'I-LOC'): 2787,\n",
       "             ('O', 'I-LOC', 'O'): 4573,\n",
       "             ('*', 'O', 'O'): 6130,\n",
       "             ('O', 'I-ORG', 'O'): 2133,\n",
       "             ('I-PER', 'I-PER', 'I-PER'): 244,\n",
       "             ('I-ORG', 'O', 'STOP'): 923,\n",
       "             ('*', 'I-PER', 'O'): 618,\n",
       "             ('I-PER', 'O', 'I-MISC'): 46,\n",
       "             ('I-LOC', 'O', 'I-LOC'): 607,\n",
       "             ('O', 'I-MISC', 'I-MISC'): 666,\n",
       "             ('I-MISC', 'I-MISC', 'I-MISC'): 295,\n",
       "             ('I-MISC', 'I-MISC', 'O'): 705,\n",
       "             ('I-MISC', 'O', 'I-MISC'): 53,\n",
       "             ('*', 'O', 'I-PER'): 968,\n",
       "             ('O', 'I-PER', 'O'): 1625,\n",
       "             ('*', '*', 'I-MISC'): 502,\n",
       "             ('*', 'I-MISC', 'O'): 324,\n",
       "             ('*', 'O', 'STOP'): 126,\n",
       "             ('*', 'O', 'I-LOC'): 376,\n",
       "             ('I-LOC', 'O', 'I-PER'): 197,\n",
       "             ('I-ORG', 'I-ORG', 'I-ORG'): 1219,\n",
       "             ('I-ORG', 'O', 'I-ORG'): 853,\n",
       "             ('O', 'I-LOC', 'I-LOC'): 837,\n",
       "             ('I-LOC', 'I-LOC', 'O'): 983,\n",
       "             ('I-LOC', 'O', 'I-MISC'): 89,\n",
       "             ('I-LOC', 'O', 'I-ORG'): 296,\n",
       "             ('I-ORG', 'O', 'I-PER'): 174,\n",
       "             ('I-PER', 'O', 'I-ORG'): 189,\n",
       "             ('I-PER', 'O', 'STOP'): 393,\n",
       "             ('*', 'I-ORG', 'I-ORG'): 883,\n",
       "             ('*', 'O', 'I-MISC'): 217,\n",
       "             ('I-ORG', 'I-ORG', 'STOP'): 72,\n",
       "             ('O', 'I-LOC', 'STOP'): 95,\n",
       "             ('I-MISC', 'O', 'I-PER'): 139,\n",
       "             ('I-PER', 'O', 'I-PER'): 541,\n",
       "             ('I-LOC', 'I-LOC', 'B-LOC'): 3,\n",
       "             ('I-LOC', 'B-LOC', 'O'): 10,\n",
       "             ('B-LOC', 'O', 'O'): 10,\n",
       "             ('I-MISC', 'O', 'STOP'): 208,\n",
       "             ('O', 'I-MISC', 'I-ORG'): 30,\n",
       "             ('I-MISC', 'I-ORG', 'O'): 25,\n",
       "             ('*', 'I-MISC', 'I-MISC'): 160,\n",
       "             ('I-ORG', 'O', 'I-LOC'): 219,\n",
       "             ('I-MISC', 'O', 'I-ORG'): 52,\n",
       "             ('I-PER', 'O', 'I-LOC'): 1499,\n",
       "             ('*', 'I-MISC', 'I-LOC'): 1,\n",
       "             ('I-MISC', 'I-LOC', 'O'): 5,\n",
       "             ('I-LOC', 'I-LOC', 'I-LOC'): 116,\n",
       "             ('I-MISC', 'O', 'I-LOC'): 45,\n",
       "             ('O', 'I-MISC', 'B-MISC'): 24,\n",
       "             ('I-MISC', 'B-MISC', 'O'): 14,\n",
       "             ('B-MISC', 'O', 'O'): 11,\n",
       "             ('*', 'I-ORG', 'STOP'): 33,\n",
       "             ('*', 'I-LOC', 'STOP'): 15,\n",
       "             ('O', 'I-ORG', 'I-MISC'): 6,\n",
       "             ('I-ORG', 'I-MISC', 'O'): 8,\n",
       "             ('O', 'I-PER', 'STOP'): 61,\n",
       "             ('*', 'I-PER', 'STOP'): 4,\n",
       "             ('*', 'I-MISC', 'B-MISC'): 7,\n",
       "             ('I-MISC', 'B-MISC', 'I-MISC'): 21,\n",
       "             ('B-MISC', 'I-MISC', 'O'): 20,\n",
       "             ('I-MISC', 'I-MISC', 'STOP'): 117,\n",
       "             ('*', 'I-LOC', 'I-LOC'): 197,\n",
       "             ('O', 'I-ORG', 'STOP'): 64,\n",
       "             ('O', 'I-MISC', 'STOP'): 23,\n",
       "             ('O', 'I-PER', 'I-MISC'): 1,\n",
       "             ('I-PER', 'I-MISC', 'O'): 1,\n",
       "             ('I-LOC', 'I-LOC', 'STOP'): 50,\n",
       "             ('O', 'I-MISC', 'I-PER'): 51,\n",
       "             ('I-MISC', 'I-PER', 'I-PER'): 59,\n",
       "             ('I-MISC', 'I-MISC', 'I-PER'): 3,\n",
       "             ('O', 'I-LOC', 'I-ORG'): 7,\n",
       "             ('I-LOC', 'I-ORG', 'O'): 9,\n",
       "             ('O', 'I-MISC', 'I-LOC'): 7,\n",
       "             ('I-MISC', 'I-MISC', 'I-ORG'): 7,\n",
       "             ('I-MISC', 'I-ORG', 'I-ORG'): 14,\n",
       "             ('O', 'I-LOC', 'I-MISC'): 19,\n",
       "             ('I-LOC', 'I-MISC', 'O'): 22,\n",
       "             ('*', 'I-LOC', 'I-ORG'): 3,\n",
       "             ('I-LOC', 'I-ORG', 'I-ORG'): 2,\n",
       "             ('I-LOC', 'I-LOC', 'I-MISC'): 3,\n",
       "             ('I-LOC', 'I-MISC', 'I-MISC'): 8,\n",
       "             ('*', 'I-LOC', 'I-MISC'): 8,\n",
       "             ('*', 'I-MISC', 'I-PER'): 7,\n",
       "             ('*', 'I-MISC', 'I-ORG'): 2,\n",
       "             ('O', 'I-ORG', 'I-PER'): 3,\n",
       "             ('I-ORG', 'I-PER', 'I-PER'): 5,\n",
       "             ('I-ORG', 'I-ORG', 'I-PER'): 3,\n",
       "             ('O', 'I-PER', 'I-LOC'): 3,\n",
       "             ('I-PER', 'I-LOC', 'I-LOC'): 1,\n",
       "             ('*', 'I-MISC', 'STOP'): 1,\n",
       "             ('B-MISC', 'O', 'I-ORG'): 3,\n",
       "             ('B-MISC', 'I-MISC', 'B-MISC'): 1,\n",
       "             ('I-MISC', 'I-LOC', 'I-LOC'): 5,\n",
       "             ('O', 'I-LOC', 'I-PER'): 1,\n",
       "             ('I-LOC', 'I-PER', 'O'): 1,\n",
       "             ('I-ORG', 'I-ORG', 'I-MISC'): 3,\n",
       "             ('I-ORG', 'I-PER', 'O'): 1,\n",
       "             ('I-MISC', 'I-PER', 'O'): 2,\n",
       "             ('I-ORG', 'I-ORG', 'I-LOC'): 1,\n",
       "             ('I-ORG', 'I-LOC', 'O'): 2,\n",
       "             ('B-MISC', 'I-MISC', 'I-MISC'): 2,\n",
       "             ('*', 'I-LOC', 'B-LOC'): 7,\n",
       "             ('I-ORG', 'I-ORG', 'B-ORG'): 6,\n",
       "             ('I-ORG', 'B-ORG', 'B-ORG'): 6,\n",
       "             ('B-ORG', 'B-ORG', 'B-ORG'): 12,\n",
       "             ('B-ORG', 'B-ORG', 'STOP'): 6,\n",
       "             ('I-MISC', 'I-MISC', 'B-MISC'): 3,\n",
       "             ('O', 'O', 'B-MISC'): 2,\n",
       "             ('O', 'B-MISC', 'I-MISC'): 2,\n",
       "             ('I-PER', 'I-LOC', 'O'): 2,\n",
       "             ('*', 'I-ORG', 'I-LOC'): 1,\n",
       "             ('I-MISC', 'I-MISC', 'I-LOC'): 2,\n",
       "             ('O', 'I-LOC', 'B-LOC'): 1,\n",
       "             ('I-LOC', 'B-LOC', 'I-LOC'): 1,\n",
       "             ('B-LOC', 'I-LOC', 'O'): 1,\n",
       "             ('I-ORG', 'I-MISC', 'I-MISC'): 1,\n",
       "             ('I-LOC', 'I-LOC', 'I-ORG'): 1})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
